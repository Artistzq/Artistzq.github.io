<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>K8s学习总结——【二】 容器网络接口（CNI）</title>
    <link href="/2024/01/14/k8s%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93_2_CNI/"/>
    <url>/2024/01/14/k8s%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93_2_CNI/</url>
    
    <content type="html"><![CDATA[<h1 id="CNI"><a href="#CNI" class="headerlink" title="CNI"></a>CNI</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p><code>Container Network Interface（CNI）</code>，即容器网络接口，是一种标准化的API规范，旨在为容器提供一致且灵活的网络配置方案。在Kubernetes环境中，Kubelet通过调用遵循CNI标准的API与各类网络插件进行交互，以实现容器间多样化的网络连接与管理。接口定义的基本操作包括 <code>ADD</code> 和 <code>DEL</code> 等，负责将Pod添加到网络和从网络中删除。</p><p>k8s通过配置文件来设置使用的CNI插件。在创建pod之前，<a id="ref1"> 管理员可以放置好CNI配置文件 </a> ，当kubelet创建pod时，通过读取配置文件，根据其中指定的CNI插件，执行相应的二进制文件，从而配置Pod网络。当kubelet对Pod执行 ADD 操作时，对应的CNI插件将为Pod分配IP地址、设置路由规则以及其他必要的网络配置；当Pod终止或被删除时，kubelet会执行 DEL 操作，这时CNI插件负责清理相关的网络资源，如释放IP地址等。</p><p>不同的CNI插件有不同的实现方式，例如Overlay和Underlay。常见的CNI插件有Calico和Flannel等，它们各自具备不同的功能特点与适用场景，从而满足不同规模、性能及安全需求的容器网络部署要求。</p><ul><li><p><code>Overlay Network</code></p><ul><li><p>是一种虚拟化技术。通过在底层数据包的基础上，添加额外的封装头部信息，借助隧道打通网络连接，可以屏蔽底层网络通信方式的差异，兼容多种异构底层网络。部署方便；扩展性好。</p></li><li><p>例如：Flannel-vxlan 插件</p></li></ul></li><li><p><code>Underlay Network</code></p><ul><li><p>提供了真正的物理层和数据链路层的连接，网络性能直接取决于硬件设备。直接基于底层传输数据，没有额外数据封装，性能高，吞吐量大，延迟低。但在异构网络环境下扩展困难，网络配置复杂。某些基于Underlay的插件无法使用复杂均衡和服务发现。</p></li><li><p>例如：clico-bgp 插件</p></li></ul></li></ul><p>实际选择时，要从多个需求出发考虑，例如安全需求、负载均衡需求、性能需求等。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="1-创建集群，不配置CNI插件"><a href="#1-创建集群，不配置CNI插件" class="headerlink" title="1 创建集群，不配置CNI插件"></a>1 创建集群，不配置CNI插件</h3><p><code>kind</code> 默认使用了 <code>kindnetd</code> 作为网络插件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">yzq@ubuntu:~$ docker <span class="hljs-built_in">exec</span> -it hello-cluster-worker <span class="hljs-built_in">ls</span> /etc/cni/net.d<br>10-kindnet.conflist<br></code></pre></td></tr></table></figure><p>为了实验，设置创建集群时不配置CNI插件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kind create cluster --name cni-test-cluster --config kind-config.yaml<br><span class="hljs-comment"># 加载本地镜像（如果不加载会出现ImagePullBackOff、ErrImagePull等错误）</span><br>$ kind load docker-image go-hello-world-image:v0.0.1 --name cni-test-cluster<br></code></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># kind-config.yaml</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Cluster</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kind.x-k8s.io/v1alpha4</span><br><span class="hljs-attr">networking:</span><br>  <span class="hljs-comment"># the default CNI will not be installed</span><br>  <span class="hljs-attr">disableDefaultCNI:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">nodes:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">control-plane</span><br>  <span class="hljs-attr">image:</span> <span class="hljs-string">kindest/node:v1.29.0</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">worker</span><br>  <span class="hljs-attr">image:</span> <span class="hljs-string">kindest/node:v1.29.0</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">worker</span><br>  <span class="hljs-attr">image:</span> <span class="hljs-string">kindest/node:v1.29.0</span><br></code></pre></td></tr></table></figure><p>查看 <code>/etc/cni/net.d</code> 下目录为空。</p><p>查看 <code>nodes</code>，状态为 not ready。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl get nodes<br>NAME                             STATUS     ROLES           AGE    VERSION<br>cni-test-cluster-control-plane   NotReady   control-plane   2d2h   v1.29.0<br>cni-test-cluster-worker          NotReady   &lt;none&gt;          2d2h   v1.29.0<br>cni-test-cluster-worker2         NotReady   &lt;none&gt;          2d2h   v1.29.0<br></code></pre></td></tr></table></figure><p>查看 <code>pods</code> 。<code>core-dns</code> 和 <code>local-path-provisioner</code> 不在运行。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl get pods --all-namespaces<br>NAMESPACE            NAME                                                     READY   STATUS    RESTARTS         AGE<br>kube-system          coredns-76f75df574-9swqg                                 0/1     Pending   0                47h<br>kube-system          coredns-76f75df574-j5mgx                                 0/1     Pending   0                47h<br>kube-system          etcd-cni-test-cluster-control-plane                      1/1     Running   0                3m7s<br>kube-system          kube-apiserver-cni-test-cluster-control-plane            1/1     Running   0                3m7s<br>kube-system          kube-controller-manager-cni-test-cluster-control-plane   1/1     Running   7 (3m25s ago)    47h<br>kube-system          kube-proxy-l8cpb                                         1/1     Running   71 (3m25s ago)   47h<br>kube-system          kube-proxy-nwpzn                                         1/1     Running   4 (3m25s ago)    47h<br>kube-system          kube-proxy-zhhfn                                         1/1     Running   71 (3m25s ago)   47h<br>kube-system          kube-scheduler-cni-test-cluster-control-plane            1/1     Running   7 (3m25s ago)    47h<br>local-path-storage   local-path-provisioner-6f8956fb48-f59n6                  0/1     Pending   0                47h<br></code></pre></td></tr></table></figure><p><code>kubectl apply -f cni-deploy.yaml</code> 部署服务后，Pod处于Pending状态。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl get pods<br>NAME                                   READY   STATUS    RESTARTS   AGE<br>cni-test-deployment-58569cd74c-qrxz5   0/1     Pending   0          142m<br>cni-test-deployment-58569cd74c-v86tf   0/1     Pending   0          142m<br>cni-test-deployment-58569cd74c-wg9rn   0/1     Pending   0          142m<br></code></pre></td></tr></table></figure><h3 id="2-手动添加flannel插件"><a href="#2-手动添加flannel插件" class="headerlink" title="2 手动添加flannel插件"></a>2 手动添加flannel插件</h3><p>Flannel插件旨在为不同节点上的容器重新规划IP地址的使用规则，分配同属一个内网且不重复的IP地址。</p><h4 id="2-1-准备好配置文件"><a href="#2-1-准备好配置文件" class="headerlink" title="2.1 准备好配置文件"></a>2.1 准备好配置文件</h4><p>如<a href="#ref1">上文</a>提到，添加CNI插件需要将配置文件放入节点的&#x2F;etc&#x2F;cni&#x2F;net.d。</p><p>可以自动化地进行。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 下载 kube-flannel.yaml 文件</span><br>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml<br><span class="hljs-comment"># 部署 flannel</span><br>kubectl apply -f kube-flannel.yml<br></code></pre></td></tr></table></figure><p>节点已经处于 <code>Ready</code> 状态。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl get nodes --all-namespaces<br>NAME                             STATUS   ROLES           AGE    VERSION<br>cni-test-cluster-control-plane   Ready    control-plane   2d2h   v1.29.0<br>cni-test-cluster-worker          Ready    &lt;none&gt;          2d2h   v1.29.0<br>cni-test-cluster-worker2         Ready    &lt;none&gt;          2d2h   v1.29.0<br></code></pre></td></tr></table></figure><p>配置文件已自动写入工作节点 <code>/etc/cni/net.d</code> 目录下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ docker <span class="hljs-built_in">exec</span> -it cni-test-cluster-worker <span class="hljs-built_in">ls</span> /etc/cni/net.d<br>10-flannel.conflist<br></code></pre></td></tr></table></figure><p>但pods依然未就绪：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl get pods --all-namespaces<br>NAMESPACE            NAME                                                     READY   STATUS              RESTARTS         AGE<br>default              cni-test-deployment-58569cd74c-qrxz5                     0/1     ContainerCreating   0                165m<br>default              cni-test-deployment-58569cd74c-v86tf                     0/1     ContainerCreating   0                165m<br>default              cni-test-deployment-58569cd74c-wg9rn                     0/1     ContainerCreating   0                165m<br>kube-flannel         kube-flannel-ds-bkl5b                                    1/1     Running             0                4m1s<br>kube-flannel         kube-flannel-ds-qfhwm                                    1/1     Running             0                4m1s<br>kube-flannel         kube-flannel-ds-xwn6m                                    1/1     Running             0                4m1s<br>kube-system          coredns-76f75df574-9swqg                                 0/1     ContainerCreating   0                2d2h<br>kube-system          coredns-76f75df574-j5mgx                                 0/1     ContainerCreating   0                2d2h<br>kube-system          etcd-cni-test-cluster-control-plane                      1/1     Running             0                5m31s<br>kube-system          kube-apiserver-cni-test-cluster-control-plane            1/1     Running             0                5m31s<br>kube-system          kube-controller-manager-cni-test-cluster-control-plane   1/1     Running             8 (6m26s ago)    2d2h<br>kube-system          kube-proxy-l8cpb                                         1/1     Running             72 (6m26s ago)   2d2h<br>kube-system          kube-proxy-nwpzn                                         1/1     Running             5 (6m26s ago)    2d2h<br>kube-system          kube-proxy-zhhfn                                         1/1     Running             72 (6m26s ago)   2d2h<br>kube-system          kube-scheduler-cni-test-cluster-control-plane            1/1     Running             8 (6m26s ago)    2d2h<br>local-path-storage   local-path-provisioner-6f8956fb48-f59n6                  0/1     ContainerCreating   0                2d2h<br><br></code></pre></td></tr></table></figure><p>通过 <code>kubectl describe pod cni-test-deployment-58569cd74c-qrxz5</code> 查看信息，提示在委派 <code>ADD</code> 操作时，无法找到 <code>/opt/cni/bin</code> 目录下的<code>bridge</code>二进制文件插件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl describe pod cni-test-deployment-58569cd74c-qrxz5<br>...<br>Conditions:<br>  Type                        Status<br>  PodReadyToStartContainers   False <br>  Initialized                 True <br>  Ready                       False <br>  ContainersReady             False <br>  PodScheduled                True <br>Events:<br>  Type     Reason                  Age                     From               Message<br>  ----     ------                  ----                    ----               -------<br>  Warning  FailedCreatePodSandBox  4m16s                   kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to setup network <span class="hljs-keyword">for</span> sandbox <span class="hljs-string">&quot;0ca3e187ace57dd4af46bb8e4c60b5b5973510f5f4a02e8efe1954d34f1b7101&quot;</span>: plugin <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;flannel&quot;</span> failed (add): failed to delegate add: failed to find plugin <span class="hljs-string">&quot;bridge&quot;</span> <span class="hljs-keyword">in</span> path [/opt/cni/bin]<br></code></pre></td></tr></table></figure><h4 id="2-2-手动安装插件的二进制文件"><a href="#2-2-手动安装插件的二进制文件" class="headerlink" title="2.2 手动安装插件的二进制文件"></a>2.2 手动安装插件的二进制文件</h4><p>在运行 kind 的宿主机上下载文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 下载文件</span><br>$ wget https://github.com/containernetworking/plugins/releases/download/v1.4.0/cni-plugins-linux-amd64-v1.4.0.tgz<br></code></pre></td></tr></table></figure><p>复制到多个工作节点（docker容器），并解压。创建脚本自动处理这一过程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ./unzip_to_docker.sh</span><br><br><span class="hljs-comment"># 获取所有名称以 &#x27;cni-test-cluster&#x27; 开头的容器</span><br>container_names=$(docker ps --format <span class="hljs-string">&quot;&#123;&#123;.Names&#125;&#125;&quot;</span> | grep <span class="hljs-string">&#x27;^cni-test-cluster&#x27;</span>)<br><br><span class="hljs-comment"># 定义本地压缩文件路径和目标解压目录（请替换为实际值）</span><br>local_archive=<span class="hljs-string">&quot;cni-plugins-linux-amd64-v1.4.0.tgz&quot;</span><br>target_directory=<span class="hljs-string">&quot;/opt/cni/bin&quot;</span><br><br><span class="hljs-comment"># 遍历每个匹配到的容器</span><br><span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> <span class="hljs-variable">$container_names</span>; <span class="hljs-keyword">do</span><br>    <span class="hljs-comment"># 将本地压缩文件复制到容器内</span><br>    docker <span class="hljs-built_in">cp</span> <span class="hljs-string">&quot;<span class="hljs-variable">$local_archive</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$name</span>:<span class="hljs-variable">$target_directory</span>&quot;</span><br>    <span class="hljs-comment"># 在容器内部执行解压命令</span><br>    docker <span class="hljs-built_in">exec</span> -it <span class="hljs-string">&quot;<span class="hljs-variable">$name</span>&quot;</span> bash -c <span class="hljs-string">&quot;cd &#x27;<span class="hljs-variable">$target_directory</span>&#x27; &amp;&amp; tar -zxvf &#x27;<span class="hljs-variable">$local_archive</span>&#x27;&quot;</span><br>    <span class="hljs-comment"># 展示文件夹下内容</span><br>    docker <span class="hljs-built_in">exec</span> -it <span class="hljs-string">&quot;<span class="hljs-variable">$name</span>&quot;</span> bash -c <span class="hljs-string">&quot;cd &#x27;<span class="hljs-variable">$target_directory</span>&#x27; &amp;&amp; ls&quot;</span><br><span class="hljs-keyword">done</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Finished deploying files to containers.&quot;</span><br></code></pre></td></tr></table></figure><p>在运行 kind 的宿主机上运行此脚本。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ bash unzip_to_docker.sh <br>Successfully copied 46.9MB to cni-test-cluster-control-plane:/opt/cni/bin<br>./<br>./loopback<br>./bandwidth<br>./ptp<br>./vlan<br>./host-device<br>./tuning<br>./vrf<br>./sbr<br>./tap<br>./dhcp<br>./static<br>./firewall<br>./macvlan<br>./dummy<br>./bridge<br>./ipvlan<br>./portmap<br>./host-local<br>bandwidth  cni-plugins-linux-amd64-v1.4.0.tgz  dummy flannel      host-local  loopback  portmap  sbr     tap     vlan<br>bridge   dhcp       firewall  host-device  ipvlan  macvlan   ptp      static  tuning  vrf<br>Successfully copied 46.9MB to cni-test-cluster-worker2:/opt/cni/bin<br>./<br>./loopback<br>./bandwidth<br>./ptp<br>./vlan<br>./host-device<br>./tuning<br>./vrf<br>./sbr<br>./tap<br>./dhcp<br>./static<br>./firewall<br>./macvlan<br>./dummy<br>./bridge<br>./ipvlan<br>./portmap<br>./host-local<br>bandwidth  cni-plugins-linux-amd64-v1.4.0.tgz  dummy flannel      host-local  loopback  portmap  sbr     tap     vlan<br>bridge   dhcp       firewall  host-device  ipvlan  macvlan   ptp      static  tuning  vrf<br>Successfully copied 46.9MB to cni-test-cluster-worker:/opt/cni/bin<br>./<br>./loopback<br>./bandwidth<br>./ptp<br>./vlan<br>./host-device<br>./tuning<br>./vrf<br>./sbr<br>./tap<br>./dhcp<br>./static<br>./firewall<br>./macvlan<br>./dummy<br>./bridge<br>./ipvlan<br>./portmap<br>./host-local<br>bandwidth  cni-plugins-linux-amd64-v1.4.0.tgz  dummy flannel      host-local  loopback  portmap  sbr     tap     vlan<br>bridge   dhcp       firewall  host-device  ipvlan  macvlan   ptp      static  tuning  vrf<br>Finished deploying files to containers.<br></code></pre></td></tr></table></figure><p>进入workNode查看网络，可以看到网卡flannel.1</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ docker <span class="hljs-built_in">exec</span> -it cni-test-cluster-worker /bin/bash<br>root@cni-test-cluster-worker:/<span class="hljs-comment"># ip a</span><br>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000<br>    <span class="hljs-built_in">link</span>/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00<br>    inet 127.0.0.1/8 scope host lo<br>       valid_lft forever preferred_lft forever<br>    inet6 ::1/128 scope host <br>       valid_lft forever preferred_lft forever<br>2: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN group default <br>    <span class="hljs-built_in">link</span>/ether a6:b3:45:67:33:b2 brd ff:ff:ff:ff:ff:ff<br>    inet 10.244.1.0/32 scope global flannel.1<br>       valid_lft forever preferred_lft forever<br>10: eth0@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default <br>    <span class="hljs-built_in">link</span>/ether 02:42:ac:12:00:04 brd ff:ff:ff:ff:ff:ff link-netnsid 0<br>    inet 172.18.0.4/16 brd 172.18.255.255 scope global eth0<br>       valid_lft forever preferred_lft forever<br>    inet6 fc00:f853:ccd:e793::4/64 scope global nodad <br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::42:acff:fe12:4/64 scope <span class="hljs-built_in">link</span> <br>       valid_lft forever preferred_lft forever<br></code></pre></td></tr></table></figure><p>进入masterNode后，检查子网环境变量，已写入。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@cni-test-cluster-control-plane:/var/run/flannel<span class="hljs-comment"># cat subnet.env </span><br>FLANNEL_NETWORK=10.244.0.0/16<br>FLANNEL_SUBNET=10.244.0.1/24<br>FLANNEL_MTU=1450<br>FLANNEL_IPMASQ=<span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p>检查pods，<code>coredns</code> 和自定义的pod <code>cni-test-deployment</code> 已正常运行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl get pods --all-namespaces<br>NAMESPACE            NAME                                                     READY   STATUS    RESTARTS       AGE<br>default              cni-test-deployment-58569cd74c-7hdmp                     1/1     Running   0              9m52s<br>default              cni-test-deployment-58569cd74c-9wcqw                     1/1     Running   0              9m52s<br>default              cni-test-deployment-58569cd74c-bbwhk                     1/1     Running   0              9m52s<br>kube-flannel         kube-flannel-ds-7dfkb                                    1/1     Running   1 (35m ago)    56m<br>kube-flannel         kube-flannel-ds-vfvbz                                    1/1     Running   1 (35m ago)    56m<br>kube-flannel         kube-flannel-ds-zc88f                                    1/1     Running   2 (34m ago)    56m<br>kube-system          coredns-76f75df574-9swqg                                 1/1     Running   0              2d3h<br>kube-system          coredns-76f75df574-j5mgx                                 1/1     Running   0              2d3h<br>kube-system          etcd-cni-test-cluster-control-plane                      1/1     Running   1 (35m ago)    95m<br>kube-system          kube-apiserver-cni-test-cluster-control-plane            1/1     Running   1 (35m ago)    95m<br>kube-system          kube-controller-manager-cni-test-cluster-control-plane   1/1     Running   9 (35m ago)    2d3h<br>kube-system          kube-proxy-l8cpb                                         1/1     Running   73 (35m ago)   2d3h<br>kube-system          kube-proxy-nwpzn                                         1/1     Running   6 (35m ago)    2d3h<br>kube-system          kube-proxy-zhhfn                                         1/1     Running   73 (35m ago)   2d3h<br>kube-system          kube-scheduler-cni-test-cluster-control-plane            1/1     Running   9 (35m ago)    2d3h<br>local-path-storage   local-path-provisioner-6f8956fb48-f59n6                  1/1     Running   0              2d3h<br></code></pre></td></tr></table></figure><p>进入在 <code>worker2</code> 节点上运行的 <code>IP = 10.244.2.7</code> 的pod ，访问在 <code>worker</code> 节点上运行的<code>IP = 10.244.1.8</code> 的pod，可以访问。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl get pods -owide<br>NAME                                   READY   STATUS    RESTARTS   AGE   IP           NODE                       NOMINATED NODE   READINESS GATES<br>cni-test-deployment-58569cd74c-7hdmp   1/1     Running   0          11m   10.244.2.7   cni-test-cluster-worker2   &lt;none&gt;           &lt;none&gt;<br>cni-test-deployment-58569cd74c-9wcqw   1/1     Running   0          11m   10.244.1.8   cni-test-cluster-worker    &lt;none&gt;           &lt;none&gt;<br>cni-test-deployment-58569cd74c-bbwhk   1/1     Running   0          11m   10.244.1.7   cni-test-cluster-worker    &lt;none&gt;           &lt;none&gt;<br><br>$ kubectl <span class="hljs-built_in">exec</span> cni-test-deployment-58569cd74c-7hdmp -it sh<br>/app <span class="hljs-comment"># curl 10.244.1.8:8080/test</span><br>hello world<br>/app <span class="hljs-comment"># exit</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>K8s</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>K8s学习总结——【一】 搭建本地集群</title>
    <link href="/2024/01/14/k8s%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93_1_%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0%E9%9B%86%E7%BE%A4/"/>
    <url>/2024/01/14/k8s%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93_1_%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<h1 id="K8s学习总结——【一】-搭建本地集群"><a href="#K8s学习总结——【一】-搭建本地集群" class="headerlink" title="K8s学习总结——【一】 搭建本地集群"></a>K8s学习总结——【一】 搭建本地集群</h1><h2 id="1-概念总结"><a href="#1-概念总结" class="headerlink" title="1 概念总结"></a>1 概念总结</h2><h3 id="1-1-kubernetes（k8s）"><a href="#1-1-kubernetes（k8s）" class="headerlink" title="1.1 kubernetes（k8s）"></a>1.1 kubernetes（k8s）</h3><ul><li>kubernetes（k8s）是用于管理云平台中的多个容器化应用的工具。</li><li>理解：<ul><li>现在的大型程序被分割为多个服务，各自运行在单独的容器里。</li><li>为了提升性能和可用性，多个容器需要分散在多个物理机器上，并拥有备份。</li><li>多个服务和容器需要通信</li><li>k8s用于自动化管理此系统。</li></ul></li></ul><h3 id="1-2-组成"><a href="#1-2-组成" class="headerlink" title="1.2 组成"></a>1.2 组成</h3><h4 id="物理层面"><a href="#物理层面" class="headerlink" title="物理层面"></a>物理层面</h4><ul><li>Master节点<ul><li>物理服务器</li><li>kubectl：操作k8s的命令行工具。添加deployment、service等。</li><li>apiServer：对象的请求和调用操作通过此模块提供的接口进行。</li><li>kube-scheduler：资源调度</li><li>kube-controller-manager：维护集群状态</li><li>etcd分布式存储：保存集群状态</li></ul></li><li>Worker节点<ul><li>物理服务器</li><li>kubelet：创建和管理pod；与master通讯</li><li>kube-proxy：负责不同pod通信。</li><li>资源（Pod等）</li></ul></li></ul><h4 id="逻辑层面"><a href="#逻辑层面" class="headerlink" title="逻辑层面"></a>逻辑层面</h4><ul><li><p>主要资源对象</p><ul><li>Container：容器化应用。</li><li>Pod：k8s创建或销毁的最小单位。一个pod包含一个或多个容器。Pod中容器共享网络、存储和计算资源。</li><li>Service：通过labels绑定pod，提供Cluster IP地址和服务名来访问Pod资源。好处是可以实现多个Pod负载均衡，并固定访问的url，Pod IP或Cluster IP变动时不会产生影响。</li><li>Deployment：管理和控制Pod的数量，确保每时每刻有用户要求数量的 Pod 在工作，某Pod出现问题就重新拉起。</li></ul></li><li><p>为了更好的提供开放、扩展、规范等能力的规范</p><ul><li>CNI：容器网络接口。定义通信规范，屏蔽底层使用不同网络插件的差异。</li><li>CSI：容器存储接口。将任意存储系统规范地暴露给容器化应用程序。</li><li>CRI：容器运行时接口。定义规范，使k8s可以兼容多种容器引擎，如docker、frakti等。</li></ul></li></ul><h2 id="2-实验操作"><a href="#2-实验操作" class="headerlink" title="2 实验操作"></a>2 实验操作</h2><h3 id="2-1-环境准备"><a href="#2-1-环境准备" class="headerlink" title="2.1 环境准备"></a>2.1 环境准备</h3><ul><li>宿主机：Windows下通过vmware运行的Ubuntu。磁盘：30GB，内存：5.2G  </li><li>选择用kind搭建集群</li></ul><h3 id="2-2-自制服务镜像"><a href="#2-2-自制服务镜像" class="headerlink" title="2.2 自制服务镜像"></a>2.2 自制服务镜像</h3><ul><li>go 服务<br>请求ip:8080&#x2F;test返回字符串”hello world”</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br>        <span class="hljs-string">&quot;fmt&quot;</span><br>        <span class="hljs-string">&quot;net/http&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">helloWorld</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>        <span class="hljs-keyword">if</span> r.Method == http.MethodGet &amp;&amp; r.URL.Path == <span class="hljs-string">&quot;/test&quot;</span> &#123;<br>                w.WriteHeader(http.StatusOK)<br>                fmt.Fprintln(w, <span class="hljs-string">&quot;hello world&quot;</span>)<br>                <span class="hljs-keyword">return</span><br>        &#125;<br>        http.NotFound(w, r)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>        http.HandleFunc(<span class="hljs-string">&quot;/test&quot;</span>, helloWorld)<br><br>        <span class="hljs-comment">// 监听并在 8080 端口启动服务</span><br>        fmt.Println(<span class="hljs-string">&quot;Server is listening on port 8080...&quot;</span>)<br>        http.ListenAndServe(<span class="hljs-string">&quot;:8080&quot;</span>, <span class="hljs-literal">nil</span>)<br>&#125;<br><br></code></pre></td></tr></table></figure><ul><li>Dockerfile</li></ul><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs Dockerfile"><span class="hljs-keyword">ARG</span> IMAGE_VERSION=v0.<span class="hljs-number">0.1</span><br><br><span class="hljs-comment"># 使用官方的Golang基础镜像作为父镜像</span><br><span class="hljs-keyword">FROM</span> golang:latest as builder<br><br><span class="hljs-comment"># 设置工作目录</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span><br><br><span class="hljs-comment"># 将项目文件复制到容器的工作目录中</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> . .</span><br><br><span class="hljs-keyword">ENV</span> CGO_ENABLED=<span class="hljs-number">0</span><br><br><span class="hljs-comment"># 构建应用</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> go build -o main .</span><br><br><span class="hljs-comment"># 使用一个新的轻量级基础镜像，例如Alpine</span><br><span class="hljs-keyword">FROM</span> alpine:latest<br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apk update</span><br><br><span class="hljs-comment"># 安装curl和其他可能需要的依赖</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apk add --no-cache curl</span><br><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span><br><br><span class="hljs-comment"># 复制编译好的二进制文件到新镜像中</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> --from=builder /app/main /app/</span><br><br><span class="hljs-comment"># 设置工作目录和提供运行时环境</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;./main&quot;</span>]</span><br><br><span class="hljs-comment"># 声明运行时容器提供的服务端口</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">8080</span><br><br></code></pre></td></tr></table></figure><ul><li>运行命令</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker build -t go-hello-world-image:v0.0.1 .<br></code></pre></td></tr></table></figure><h3 id="2-3-kind创建集群"><a href="#2-3-kind创建集群" class="headerlink" title="2.3 kind创建集群"></a>2.3 kind创建集群</h3><ul><li>文件结构</li></ul><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs txt">├── go-hello<br>│   ├── app<br>│   ├── Dockerfile<br>│   ├── go.mod<br>│   └── main.go<br>├── hello-deploy.yaml<br>├── hello-service.yaml<br>├── kind-config.yaml<br>├── nginx-deployment.yaml<br>└── nginx-service.yaml<br></code></pre></td></tr></table></figure><ul><li>集群配置文件：kind-config.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">kind:</span> <span class="hljs-string">Cluster</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kind.x-k8s.io/v1alpha4</span><br><span class="hljs-attr">nodes:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">control-plane</span><br>  <span class="hljs-attr">image:</span> <span class="hljs-string">kindest/node:v1.29.0</span> <span class="hljs-comment"># 指定worknode镜像</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">worker</span><br>  <span class="hljs-attr">image:</span> <span class="hljs-string">kindest/node:v1.29.0</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">worker</span><br>  <span class="hljs-attr">image:</span> <span class="hljs-string">kindest/node:v1.29.0</span><br></code></pre></td></tr></table></figure><ul><li>deployment配置文件：hello-deploy.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">go-hello-world-deployment</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">3</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">matchLabels:</span><br>      <span class="hljs-attr">app:</span> <span class="hljs-string">go-hello-world</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app:</span> <span class="hljs-string">go-hello-world</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">containers:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">go-hello-world-container</span><br>        <span class="hljs-attr">image:</span> <span class="hljs-string">go-hello-world-image:v0.0.1</span> <span class="hljs-comment"># 替换为您的镜像名称和标签</span><br>        <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>        <span class="hljs-attr">ports:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">8080</span> <span class="hljs-comment"># 假设服务监听在容器内部的8080端口</span><br></code></pre></td></tr></table></figure><ul><li>service配置文件：hello-service.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">hello-service</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">NodePort</span> <span class="hljs-comment"># 或者 LoadBalancer 如果在模拟云环境中</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">go-hello-world</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">port:</span> <span class="hljs-number">30007</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">8080</span><br>    <span class="hljs-attr">nodePort:</span> <span class="hljs-number">30008</span> <span class="hljs-comment"># 如果是NodePort类型，设置一个可用端口</span><br></code></pre></td></tr></table></figure><ul><li>搭建集群</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建集群</span><br>kind create cluster --name hello-cluster --config kind-config.yaml<br><span class="hljs-comment"># 加载镜像</span><br>kind load docker-image go-hello-world-image:v0.0.1 --name hello-cluster<br><span class="hljs-comment"># 创建 deployment</span><br>kubectl apply -f hello-deploy.yaml<br><span class="hljs-comment"># 创建 service</span><br>kubectl apply -f hello-service.yaml<br></code></pre></td></tr></table></figure><ul><li>Docker信息概览</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">yzq@ubuntu:~/Documents/k8s-proj/hello$ docker ps<br>CONTAINER ID   IMAGE                         COMMAND                  CREATED       STATUS       PORTS                                         NAMES<br>a20802131005   kindest/node:v1.29.0          <span class="hljs-string">&quot;/usr/local/bin/entr…&quot;</span>   4 hours ago   Up 4 hours                                                 hello-cluster-worker<br>710f6226c8ab   kindest/node:v1.29.0          <span class="hljs-string">&quot;/usr/local/bin/entr…&quot;</span>   4 hours ago   Up 4 hours   127.0.0.1:35839-&gt;6443/tcp                     hello-cluster-control-plane<br>c21dc643b049   kindest/node:v1.29.0          <span class="hljs-string">&quot;/usr/local/bin/entr…&quot;</span>   4 hours ago   Up 4 hours                                                 hello-cluster-worker2<br>bc232db8553e   go-hello-world-image:v0.0.1   <span class="hljs-string">&quot;./main&quot;</span>                 4 hours ago   Up 4 hours   0.0.0.0:10086-&gt;8080/tcp, :::10086-&gt;8080/tcp   hello-local<br></code></pre></td></tr></table></figure><ul><li>nodes信息</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">yzq@ubuntu:~/Documents/k8s-proj/hello$ kubectl get nodes -o wide<br>NAME                          STATUS   ROLES           AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION      CONTAINER-RUNTIME<br>hello-cluster-control-plane   Ready    control-plane   3h41m   v1.29.0   172.18.0.2    &lt;none&gt;        Debian GNU/Linux 11 (bullseye)   5.15.0-91-generic   containerd://1.7.1<br>hello-cluster-worker          Ready    &lt;none&gt;          3h41m   v1.29.0   172.18.0.4    &lt;none&gt;        Debian GNU/Linux 11 (bullseye)   5.15.0-91-generic   containerd://1.7.1<br>hello-cluster-worker2         Ready    &lt;none&gt;          3h41m   v1.29.0   172.18.0.3    &lt;none&gt;        Debian GNU/Linux 11 (bullseye)   5.15.0-91-generic   containerd://1.7.1<br></code></pre></td></tr></table></figure><ul><li>pods信息</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">yzq@ubuntu:~/Documents/k8s-proj/hello$ kubectl get pods -o wide<br>NAME                                         READY   STATUS    RESTARTS   AGE     IP           NODE                    NOMINATED NODE   READINESS GATES<br>go-hello-world-deployment-58569cd74c-85hw5   1/1     Running   0          3h33m   10.244.1.5   hello-cluster-worker    &lt;none&gt;           &lt;none&gt;<br>go-hello-world-deployment-58569cd74c-bd8ht   1/1     Running   0          3h33m   10.244.2.3   hello-cluster-worker2   &lt;none&gt;           &lt;none&gt;<br>go-hello-world-deployment-58569cd74c-qgfm7   1/1     Running   0          3h33m   10.244.1.4   hello-cluster-worker    &lt;none&gt;           &lt;none&gt;<br></code></pre></td></tr></table></figure><ul><li>service信息</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">yzq@ubuntu:~/Documents/k8s-proj/hello$ kubectl get service -o wide<br>NAME            TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE     SELECTOR<br>hello-service   NodePort    10.96.2.242   &lt;none&gt;        8080:30008/TCP   3h13m   app=go-hello-world<br>kubernetes      ClusterIP   10.96.0.1     &lt;none&gt;        443/TCP          3h42m   &lt;none&gt;<br></code></pre></td></tr></table></figure><h3 id="2-4-结果与问题"><a href="#2-4-结果与问题" class="headerlink" title="2.4 结果与问题"></a>2.4 结果与问题</h3><p>使用Kind创建了集群。自定义的服务监听 <code>port = 8080</code>，service监听 <code>sport = 30007</code>，在workNode上开放 <code>NodePort=30008</code>。</p><h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><h5 id="1-进入到pod内部"><a href="#1-进入到pod内部" class="headerlink" title="1 进入到pod内部"></a>1 进入到pod内部</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">yzq@ubuntu:~/Documents/k8s-proj/hello$ kubectl <span class="hljs-built_in">exec</span> -it go-hello-world-deployment-58569cd74c-85hw5 sh<br>kubectl <span class="hljs-built_in">exec</span> [POD] [COMMAND] is DEPRECATED and will be removed <span class="hljs-keyword">in</span> a future version. Use kubectl <span class="hljs-built_in">exec</span> [POD] -- [COMMAND] instead.<br>/app <span class="hljs-comment"># curl localhost:8080/test</span><br>hello world<br>/app <span class="hljs-comment"># curl 10.244.1.4:8080/test</span><br>hello world<br>/app <span class="hljs-comment"># curl 10.96.2.242:30007/test</span><br>hello world<br>/app <span class="hljs-comment"># curl hello-service:30007/test</span><br>hello world<br></code></pre></td></tr></table></figure><ul><li>可以用 <code>localhost:port</code>访问本pod服务</li><li>可以用 <code>pod ip:port</code>访问对应pod的服务</li><li>创建Service后，可以用 <code>clusterIP:sport</code>可以访问服务</li><li>创建Service后，<strong>无法</strong>通过 <code>hello-service:sport</code>访问服务 <a href="#bug1">[1]</a></li></ul><h5 id="2-进入到workNode内部"><a href="#2-进入到workNode内部" class="headerlink" title="2 进入到workNode内部"></a>2 进入到workNode内部</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">exec</span> -it hello-cluster-worker sh<br></code></pre></td></tr></table></figure><ul><li>使用 <code>localhost:NodePort</code>可以访问本workNode上的服务；</li><li>使用 <code>WorkNodeIp:NodePort</code>和 <code>其他WorkNodeIp:NodePort</code><strong>无法</strong>访问服务 <a href="#bug2">[2]</a></li></ul><h4 id="问题与解决"><a href="#问题与解决" class="headerlink" title="问题与解决"></a>问题与解决</h4><p><a id="bug1">[1]</a> 检查kube-dns，无明显错误，重启后解决。</p><p><a id="bug2">[2]</a> 排查过程如下：</p><ul><li><p>检查 <code>ufw</code>防火墙：未开启防火墙</p></li><li><p>检查CNI日志，workNode拥有子网段，可以分配给pod<br>Node hello-cluster-control-plane has CIDR [<code>10.244.0.0/24</code>]<br>Node hello-cluster-worker has CIDR [<code>10.244.1.0/24</code>]<br>Node hello-cluster-worker2 has CIDR [<code>10.244.2.0/24</code>]</p></li><li><p>检查 <code>ping</code>：可以ping通IP</p></li><li><p>通过 <code>curl -v</code> 查看详细信息，发现走了代理 <code>192.168.115.1</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Windows的IP为192.168.115.1；在这个windows里面，我运行了一个ubuntu虚拟机，IP为192.168.115.128；</span><br><span class="hljs-comment"># windows上的7890端口设置了代理服务器，用于访问资源；</span><br><span class="hljs-comment"># 为了让ubuntu虚拟机同样能够访问资源，我配置ubuntu的代理服务器为192.168.115.1:7890；   </span><br><br>curl -v 172.18.0.3:30008<br><br>* Uses proxy <span class="hljs-built_in">env</span> variable no_proxy == <span class="hljs-string">&#x27;172.18.0.0/16,fc00:f853:ccd:e793::/64,localhost,127.0.0.1,10.96.0.0/12,192.168.59.0/24,192.168.49.0/24,192.168.39.0/24,::1,10.96.0.0/16,10.244.0.0/16,hello-cluster-control-plane,hello-cluster-worker,hello-cluster-worker2,.svc,.svc.cluster,.svc.cluster.local&#x27;</span><br>* Uses proxy <span class="hljs-built_in">env</span> variable http_proxy == <span class="hljs-string">&#x27;http://192.168.115.1:7890/&#x27;</span><br>*   Trying 192.168.115.1:7890...<br>* Connected to 192.168.115.1 (192.168.115.1) port 7890 (<span class="hljs-comment">#0)</span><br>&gt; GET http://172.18.0.3:30008/ HTTP/1.1<br>&gt; Host: 172.18.0.3:30008<br>&gt; User-Agent: curl/7.74.0<br>&gt; Accept: */*<br>&gt; Proxy-Connection: Keep-Alive<br>&gt; <br>* Mark bundle as not supporting multiuse<br>&lt; HTTP/1.1 502 Bad Gateway<br>&lt; Connection: keep-alive<br>&lt; Keep-Alive: <span class="hljs-built_in">timeout</span>=4<br>&lt; Proxy-Connection: keep-alive<br>&lt; Content-Length: 0<br>&lt; <br></code></pre></td></tr></table></figure></li><li><p><code>curl --noproxy</code>：强制使用curl不走代理，访问成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># curl -v --noproxy &#x27;*&#x27; 172.18.0.3:30008/test</span><br>hello world<br></code></pre></td></tr></table></figure></li><li><p>检查workNode上的环境变量：确实存在no_proxy环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># env | grep no_proxy</span><br>no_proxy=172.18.0.0/16,fc00:f853:ccd:e793::/64,localhost,127.0.0.1,10.96.0.0/12,192.168.59.0/24,192.168.49.0/24,192.168.39.0/24,::1,10.96.0.0/16,10.244.0.0/16,hello-cluster-control-plane,hello-cluster-worker,hello-cluster-worker2,.svc,.svc.cluster,.svc.cluster.local<span class="hljs-string">&#x27;</span><br></code></pre></td></tr></table></figure></li><li><p>使用其他工具 <code>wget</code>访问接口：也走了代理</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># wget -O - http://172.18.0.3:30008/test</span><br></code></pre></td></tr></table></figure></li><li><p>现在问题已经在于：在kind创建的这个workNode中，path包含了proxy和no_proxy，但no_proxy没有起作用，在curl和wget都出现这个现象。</p></li><li><p>回到vmware ubuntu界面，把整个虚拟机的代理关闭。</p></li><li><p>重新创建集群，使用<code>workNode:NodePort</code><strong>可以</strong>访问。</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>K8s</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
